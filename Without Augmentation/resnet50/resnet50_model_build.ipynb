{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3134515,"sourceType":"datasetVersion","datasetId":1909705}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install torch torchvision kagglehub matplotlib seaborn tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:23:07.441330Z","iopub.execute_input":"2025-03-28T10:23:07.441708Z","iopub.status.idle":"2025-03-28T10:23:12.444220Z","shell.execute_reply.started":"2025-03-28T10:23:07.441677Z","shell.execute_reply":"2025-03-28T10:23:12.443347Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport copy\nimport time\nimport torch\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom torch import nn, optim\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve\nfrom tqdm import tqdm\nimport kagglehub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:23:12.445361Z","iopub.execute_input":"2025-03-28T10:23:12.445680Z","iopub.status.idle":"2025-03-28T10:23:19.886495Z","shell.execute_reply.started":"2025-03-28T10:23:12.445653Z","shell.execute_reply":"2025-03-28T10:23:19.885609Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:23:19.887693Z","iopub.execute_input":"2025-03-28T10:23:19.888146Z","iopub.status.idle":"2025-03-28T10:23:19.961285Z","shell.execute_reply.started":"2025-03-28T10:23:19.888119Z","shell.execute_reply":"2025-03-28T10:23:19.960167Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Download dataset\npath = kagglehub.dataset_download(\"manjilkarki/deepfake-and-real-images\")\ndataset_dir = os.path.join(path, \"Dataset\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:23:21.884294Z","iopub.execute_input":"2025-03-28T10:23:21.884718Z","iopub.status.idle":"2025-03-28T10:23:22.018987Z","shell.execute_reply.started":"2025-03-28T10:23:21.884680Z","shell.execute_reply":"2025-03-28T10:23:22.018117Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define transforms\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor(),\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor(),\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor(),\n    ]),\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:23:23.657720Z","iopub.execute_input":"2025-03-28T10:23:23.658004Z","iopub.status.idle":"2025-03-28T10:23:23.662662Z","shell.execute_reply.started":"2025-03-28T10:23:23.657981Z","shell.execute_reply":"2025-03-28T10:23:23.661682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load datasets\ntrain_dataset = datasets.ImageFolder(os.path.join(dataset_dir, \"Train\"), data_transforms['train'])\nval_dataset = datasets.ImageFolder(os.path.join(dataset_dir, \"Validation\"), data_transforms['val'])\ntest_dataset = datasets.ImageFolder(os.path.join(dataset_dir, \"Test\"), data_transforms['test'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:23:26.776474Z","iopub.execute_input":"2025-03-28T10:23:26.776759Z","iopub.status.idle":"2025-03-28T10:26:41.440387Z","shell.execute_reply.started":"2025-03-28T10:23:26.776738Z","shell.execute_reply":"2025-03-28T10:26:41.439423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create dataloaders\nbatch_size = 32\ndataloaders = {\n    'train': DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4),\n    'val': DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4),\n    'test': DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:45:25.314196Z","iopub.execute_input":"2025-03-28T10:45:25.314560Z","iopub.status.idle":"2025-03-28T10:45:25.319030Z","shell.execute_reply.started":"2025-03-28T10:45:25.314532Z","shell.execute_reply":"2025-03-28T10:45:25.318256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_dataset_insights(dataset, split_name):\n    # Calculate class counts\n    class_counts = {cls: 0 for cls in dataset.classes}\n    for _, label in dataset.samples:\n        class_counts[dataset.classes[label]] += 1\n\n    # Prepare data for plotting\n    classes = list(class_counts.keys())\n    counts = list(class_counts.values())\n\n    # Create bar plot\n    plt.figure(figsize=(6, 4))\n    bars = plt.bar(classes, counts, color=['skyblue', 'salmon'])\n    plt.title(f\"{split_name} Dataset Insights\")\n    plt.xlabel(\"Class\")\n    plt.ylabel(\"Number of images\")\n\n    # Add text labels on top of each bar\n    for bar in bars:\n        yval = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.05*yval, f'{yval}', ha='center', va='bottom')\n\n    plt.show()\n\n# Plot insights for each dataset split\nplot_dataset_insights(train_dataset, \"Train\")\nplot_dataset_insights(val_dataset, \"Validation\")\nplot_dataset_insights(test_dataset, \"Test\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:45:28.398297Z","iopub.execute_input":"2025-03-28T10:45:28.398624Z","iopub.status.idle":"2025-03-28T10:45:28.941999Z","shell.execute_reply.started":"2025-03-28T10:45:28.398595Z","shell.execute_reply":"2025-03-28T10:45:28.941325Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize ResNet50\nmodel = models.resnet50(pretrained=True)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 1)\n\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n    model = nn.DataParallel(model)\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:45:43.378410Z","iopub.execute_input":"2025-03-28T10:45:43.378868Z","iopub.status.idle":"2025-03-28T10:45:45.515597Z","shell.execute_reply.started":"2025-03-28T10:45:43.378825Z","shell.execute_reply":"2025-03-28T10:45:45.514686Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training setup\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, min_lr=1e-7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:45:49.468158Z","iopub.execute_input":"2025-03-28T10:45:49.468481Z","iopub.status.idle":"2025-03-28T10:45:49.473645Z","shell.execute_reply.started":"2025-03-28T10:45:49.468455Z","shell.execute_reply":"2025-03-28T10:45:49.472759Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configuration for training loop\nnum_epochs = 20\nearly_stop_patience = 3\nbest_auc = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:45:52.358252Z","iopub.execute_input":"2025-03-28T10:45:52.358586Z","iopub.status.idle":"2025-03-28T10:45:52.362572Z","shell.execute_reply.started":"2025-03-28T10:45:52.358556Z","shell.execute_reply":"2025-03-28T10:45:52.361700Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n    \n    for phase in ['train', 'val']:\n        if phase == 'train':\n            model.train()\n        else:\n            model.eval()\n            \n        running_loss = 0.0\n        correct = 0\n        total = 0\n        all_labels = []\n        all_preds = []\n        \n        # Wrap dataloader with tqdm for batch-level progress\n        pbar = tqdm(dataloaders[phase], desc=f\"{phase.capitalize()} Phase\", leave=False)\n        for inputs, labels in pbar:\n            inputs = inputs.to(device)\n            labels = labels.to(device).float().unsqueeze(1)\n            \n            with torch.set_grad_enabled(phase == 'train'):\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                \n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n                    optimizer.zero_grad()\n                \n            running_loss += loss.item() * inputs.size(0)\n            preds = torch.sigmoid(outputs).detach().cpu().numpy()\n            batch_preds = (preds >= 0.5).astype(int)\n            batch_labels = labels.cpu().numpy().astype(int)\n            \n            all_preds.extend(preds.flatten())\n            all_labels.extend(batch_labels.flatten())\n            correct += (batch_preds == batch_labels).sum()\n            total += inputs.size(0)\n            \n            pbar.set_postfix({\n                \"Loss\": f\"{loss.item():.4f}\",\n                \"Acc\": f\"{(batch_preds == batch_labels).mean():.4f}\"\n            })\n        \n        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n        epoch_acc = correct / total\n        epoch_auc = roc_auc_score(all_labels, all_preds)\n        current_lr = optimizer.param_groups[0]['lr']\n        \n        print(f\"{phase.capitalize()} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}, AUC: {epoch_auc:.4f}, LR: {current_lr:.6f}\")\n\n        if phase == 'val':\n            scheduler.step(epoch_auc)\n            if epoch_auc > best_auc:\n                best_auc = epoch_auc\n                best_model_wts = copy.deepcopy(model.state_dict())\n                torch.save(model.state_dict(), 'best_model.pth')\n                epochs_no_improve = 0\n            else:\n                epochs_no_improve += 1\n\n    if epochs_no_improve >= early_stop_patience:\n        print(\"Early stopping triggered\")\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T10:45:56.888914Z","iopub.execute_input":"2025-03-28T10:45:56.889262Z","iopub.status.idle":"2025-03-28T15:17:48.721467Z","shell.execute_reply.started":"2025-03-28T10:45:56.889232Z","shell.execute_reply":"2025-03-28T15:17:48.720630Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model, \"final_model_resnet50.pth\");","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T15:28:24.630541Z","iopub.execute_input":"2025-03-28T15:28:24.630868Z","iopub.status.idle":"2025-03-28T15:28:24.785842Z","shell.execute_reply.started":"2025-03-28T15:28:24.630839Z","shell.execute_reply":"2025-03-28T15:28:24.784690Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Testing phase with detailed metrics\nmodel.eval()\ntest_loss = 0.0\ncorrect = 0\ntotal = 0\nall_labels = []\nall_preds = []\n\npbar_test = tqdm(dataloaders['test'], desc=\"Testing Phase\", leave=False)\nwith torch.no_grad():\n    for inputs, labels in pbar_test:\n        inputs = inputs.to(device)\n        labels = labels.to(device).float().unsqueeze(1)\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        \n        test_loss += loss.item() * inputs.size(0)\n        preds = torch.sigmoid(outputs).cpu().numpy()\n        batch_preds = (preds >= 0.5).astype(int)\n        batch_labels = labels.cpu().numpy().astype(int)\n        \n        all_preds.extend(preds.flatten())\n        all_labels.extend(batch_labels.flatten())\n        correct += (batch_preds == batch_labels).sum()\n        total += inputs.size(0)\n        \n        pbar_test.set_postfix({\n            \"Loss\": f\"{loss.item():.4f}\",\n            \"Acc\": f\"{(batch_preds == batch_labels).mean():.4f}\"\n        })\n\ntest_loss = test_loss / len(dataloaders['test'].dataset)\ntest_acc = correct / total\ntest_auc = roc_auc_score(all_labels, all_preds)\ncurrent_lr = optimizer.param_groups[0]['lr']\n\nprint(\"\\nTest Metrics:\")\nprint(f\"Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, AUC: {test_auc:.4f}, LR: {current_lr:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T15:29:08.208186Z","iopub.execute_input":"2025-03-28T15:29:08.208480Z","iopub.status.idle":"2025-03-28T15:29:45.068673Z","shell.execute_reply.started":"2025-03-28T15:29:08.208457Z","shell.execute_reply":"2025-03-28T15:29:45.067723Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Confusion Matrix\ncm = confusion_matrix(all_labels, (np.array(all_preds) >= 0.5))\nplt.figure(figsize=(6, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\nplt.title('Confusion Matrix')\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T15:30:23.617744Z","iopub.execute_input":"2025-03-28T15:30:23.618111Z","iopub.status.idle":"2025-03-28T15:30:23.795787Z","shell.execute_reply.started":"2025-03-28T15:30:23.618052Z","shell.execute_reply":"2025-03-28T15:30:23.795035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ROC Curve\nfpr, tpr, _ = roc_curve(all_labels, all_preds)\nplt.figure()\nplt.plot(fpr, tpr, label=f'AUC = {test_auc:.2f}')\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T15:30:46.618874Z","iopub.execute_input":"2025-03-28T15:30:46.619210Z","iopub.status.idle":"2025-03-28T15:30:46.797188Z","shell.execute_reply.started":"2025-03-28T15:30:46.619183Z","shell.execute_reply":"2025-03-28T15:30:46.796463Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.load_state_dict(best_model_wts)\n\ntorch.save(model, \"best_model_resnet50.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T15:34:21.064523Z","iopub.execute_input":"2025-03-28T15:34:21.064815Z","iopub.status.idle":"2025-03-28T15:34:21.227826Z","shell.execute_reply.started":"2025-03-28T15:34:21.064793Z","shell.execute_reply":"2025-03-28T15:34:21.227163Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Testing for best_model\nmodel.eval()\ntest_loss = 0.0\ncorrect = 0\ntotal = 0\nall_labels = []\nall_preds = []\n\npbar_test = tqdm(dataloaders['test'], desc=\"Testing Phase\", leave=False)\nwith torch.no_grad():\n    for inputs, labels in pbar_test:\n        inputs = inputs.to(device)\n        labels = labels.to(device).float().unsqueeze(1)\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        \n        test_loss += loss.item() * inputs.size(0)\n        preds = torch.sigmoid(outputs).cpu().numpy()\n        batch_preds = (preds >= 0.5).astype(int)\n        batch_labels = labels.cpu().numpy().astype(int)\n        \n        all_preds.extend(preds.flatten())\n        all_labels.extend(batch_labels.flatten())\n        correct += (batch_preds == batch_labels).sum()\n        total += inputs.size(0)\n        \n        pbar_test.set_postfix({\n            \"Loss\": f\"{loss.item():.4f}\",\n            \"Acc\": f\"{(batch_preds == batch_labels).mean():.4f}\"\n        })\n\ntest_loss = test_loss / len(dataloaders['test'].dataset)\ntest_acc = correct / total\ntest_auc = roc_auc_score(all_labels, all_preds)\ncurrent_lr = optimizer.param_groups[0]['lr']\n\nprint(\"\\nTest Metrics:\")\nprint(f\"Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, AUC: {test_auc:.4f}, LR: {current_lr:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T15:34:33.146476Z","iopub.execute_input":"2025-03-28T15:34:33.146762Z","iopub.status.idle":"2025-03-28T15:35:07.044774Z","shell.execute_reply.started":"2025-03-28T15:34:33.146741Z","shell.execute_reply":"2025-03-28T15:35:07.043822Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Confusion Matrix\ncm = confusion_matrix(all_labels, (np.array(all_preds) >= 0.5))\nplt.figure(figsize=(6, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\nplt.title('Confusion Matrix')\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T15:35:14.617515Z","iopub.execute_input":"2025-03-28T15:35:14.617822Z","iopub.status.idle":"2025-03-28T15:35:14.793438Z","shell.execute_reply.started":"2025-03-28T15:35:14.617795Z","shell.execute_reply":"2025-03-28T15:35:14.792616Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ROC Curve\nfpr, tpr, _ = roc_curve(all_labels, all_preds)\nplt.figure()\nplt.plot(fpr, tpr, label=f'AUC = {test_auc:.2f}')\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T15:35:24.341174Z","iopub.execute_input":"2025-03-28T15:35:24.341484Z","iopub.status.idle":"2025-03-28T15:35:24.520223Z","shell.execute_reply.started":"2025-03-28T15:35:24.341454Z","shell.execute_reply":"2025-03-28T15:35:24.519380Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve, average_precision_score\n\nprecision, recall, thresholds = precision_recall_curve(all_labels, all_preds)\nap = average_precision_score(all_labels, all_preds)\n\nplt.figure(figsize=(6, 4))\nplt.step(recall, precision, where='post', label=f'AP = {ap:.2f}')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T15:42:42.877488Z","iopub.execute_input":"2025-03-28T15:42:42.877797Z","iopub.status.idle":"2025-03-28T15:42:43.078274Z","shell.execute_reply.started":"2025-03-28T15:42:42.877773Z","shell.execute_reply":"2025-03-28T15:42:43.077432Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(6, 4))\nplt.hist(all_preds, bins=20, alpha=0.7, color='gray')\nplt.xlabel('Predicted Probability')\nplt.ylabel('Frequency')\nplt.title('Histogram of Predicted Probabilities')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T15:43:05.807159Z","iopub.execute_input":"2025-03-28T15:43:05.807452Z","iopub.status.idle":"2025-03-28T15:43:05.999269Z","shell.execute_reply.started":"2025-03-28T15:43:05.807428Z","shell.execute_reply":"2025-03-28T15:43:05.998397Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.calibration import calibration_curve\n\nprob_true, prob_pred = calibration_curve(all_labels, all_preds, n_bins=10)\n\nplt.figure(figsize=(6, 4))\nplt.plot(prob_pred, prob_true, marker='o', linewidth=1, label='Calibration curve')\nplt.plot([0, 1], [0, 1], linestyle='--', label='Perfect calibration')\nplt.xlabel('Mean predicted probability')\nplt.ylabel('Fraction of positives')\nplt.title('Calibration Plot')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T15:44:13.484901Z","iopub.execute_input":"2025-03-28T15:44:13.485251Z","iopub.status.idle":"2025-03-28T15:44:13.831661Z","shell.execute_reply.started":"2025-03-28T15:44:13.485222Z","shell.execute_reply":"2025-03-28T15:44:13.830883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\n# Compute F1 score for a range of thresholds\nthresholds = np.linspace(0, 1, 100)\nf1_scores = [f1_score(all_labels, (np.array(all_preds) >= t).astype(int)) for t in thresholds]\n\nplt.figure(figsize=(6, 4))\nplt.plot(thresholds, f1_scores, marker='o')\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"F1 Score\")\nplt.title(\"F1 Score vs Threshold\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T15:45:20.106188Z","iopub.execute_input":"2025-03-28T15:45:20.106529Z","iopub.status.idle":"2025-03-28T15:45:20.925527Z","shell.execute_reply.started":"2025-03-28T15:45:20.106500Z","shell.execute_reply":"2025-03-28T15:45:20.924658Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Create a DataFrame with true labels and predicted probabilities\ndf = pd.DataFrame({\"label\": all_labels, \"pred\": all_preds})\ndf = df.sort_values(\"pred\", ascending=False).reset_index(drop=True)\ndf[\"cumulative_positive\"] = df[\"label\"].cumsum()\ndf[\"percentage_positive\"] = df[\"cumulative_positive\"] / df[\"label\"].sum()\ndf[\"percentage_data\"] = (df.index + 1) / len(df)\n\nplt.figure(figsize=(6, 4))\nplt.plot(df[\"percentage_data\"], df[\"percentage_positive\"], label=\"Model\")\nplt.plot([0, 1], [0, 1], linestyle=\"--\", label=\"Random\")\nplt.xlabel(\"Percentage of Data\")\nplt.ylabel(\"Percentage of Positives Captured\")\nplt.title(\"Cumulative Gains Chart\")\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T15:45:39.013049Z","iopub.execute_input":"2025-03-28T15:45:39.013355Z","iopub.status.idle":"2025-03-28T15:45:39.245312Z","shell.execute_reply.started":"2025-03-28T15:45:39.013330Z","shell.execute_reply":"2025-03-28T15:45:39.244577Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}